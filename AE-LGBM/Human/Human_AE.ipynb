{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TÁI LẬP TRÌNH TỪ BÀI BÁO GỐC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng siêu tham số từ bài báo gốc\n",
    "Sử dụng chương trình trích xuất đặc trưng được cung cấp từ bài báo gốc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\NCSI\\3 - Thuc nghiem\\ModifiedModel\\AE_LGBM_2020\\mod_AE_LGBM\\_original\\Human\")\n",
    "\n",
    "label = pd.read_csv(\"label.csv\")\n",
    "# print(label)\n",
    "feat_a = pd.read_csv(\"total_features_a.csv\")\n",
    "# print(feat_a)\n",
    "feat_b = pd.read_csv(\"total_features_b.csv\")\n",
    "# print(feat_b)\n",
    "feat_all = pd.concat([feat_a, feat_b], axis=1)\n",
    "print(feat_all.shape)\n",
    "\n",
    "X_no_enc = feat_all.values\n",
    "y_no_enc = label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "def AE_net(n_col, k = 208):\n",
    "    model_AE = Sequential(\n",
    "        [\n",
    "            Dense(k, activation = 'sigmoid', input_shape=(n_col,)),\n",
    "            Dropout(rate = 0.2),\n",
    "            Dense(n_col, activation = 'sigmoid', input_shape=(k,))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Constructing Autoencoder\n",
    "    model_AE.compile(optimizer='nadam',\n",
    "                      loss= 'mean_squared_error',\n",
    "                      metrics = \"accuracy\")\n",
    "\n",
    "    # model_AE1.summary()\n",
    "    enc_net = Model(inputs=model_AE.input,\n",
    "                    outputs=model_AE.layers[1].output)\n",
    "    # enc_net.summary()\n",
    "    return model_AE, enc_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the Autoencoder for chain A. B\n",
    "k = 208\n",
    "n_col = feat_a.shape[1]\n",
    "model_AE1, enc_a = AE_net(n_col, k)\n",
    "\n",
    "# Fitting the Autoencoder\n",
    "print(\"\\nHuan luyen AE 1...\")\n",
    "print(f\"feat_a {feat_a.shape}\")\n",
    "history_a = model_AE1.fit(feat_a, feat_a,\n",
    "                          epochs=200,\n",
    "                          batch_size=50,\n",
    "                          validation_split = 0.2,\n",
    "                          verbose=0)\n",
    "\n",
    "feat_a_enc = enc_a.predict(feat_a)\n",
    "print(\"feat_a_enc\", feat_a_enc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nHuan luyen AE 2...\")\n",
    "print(f\"feat_b {feat_b.shape}\")\n",
    "model_AE2, enc_b = AE_net(n_col, k)\n",
    "history_b = model_AE2.fit(feat_b, feat_b,\n",
    "                          epochs=200,\n",
    "                          batch_size=50,\n",
    "                          validation_split = 0.2,\n",
    "                          verbose=0)\n",
    "\n",
    "feat_b_enc = enc_b.predict(feat_b)\n",
    "print(feat_b_enc.shape)\n",
    "\n",
    "# --- Save\n",
    "from utils import pickleplus\n",
    "pickleplus.dump(feat_b_enc, \"human_enc_feat_b.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SỬ DỤNG LẠI MÔ HÌNH ĐÃ ĐƯỢC HUẤN LUYỆN CỦA BÀI BÀO GỐC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8161, 1232)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"D:\\NCSI\\3 - Thuc nghiem\\ModifiedModel\\AE_LGBM_2020\\mod_AE_LGBM\\_original\\Human\")\n",
    "\n",
    "label = pd.read_csv(\"label.csv\")\n",
    "feat_a = pd.read_csv(\"total_features_a.csv\")\n",
    "feat_b = pd.read_csv(\"total_features_b.csv\")\n",
    "feat_all = pd.concat([feat_a, feat_b], axis=1)\n",
    "print(feat_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 208)               128336    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 208)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 616)               128744    \n",
      "=================================================================\n",
      "Total params: 257,080\n",
      "Trainable params: 257,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(8161, 616)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 208)               128336    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 208)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 616)               128744    \n",
      "=================================================================\n",
      "Total params: 257,080\n",
      "Trainable params: 257,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(8161, 616)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "enc_a = load_model(\"AE_Human_a_.h5\")\n",
    "print(enc_a.summary())\n",
    "\n",
    "X_no_enc = feat_all.values\n",
    "y_no_enc = label.values\n",
    "\n",
    "feat_a_enc = enc_a.predict(feat_a)\n",
    "print(feat_a_enc.shape)\n",
    "\n",
    "enc_b = load_model(\"AE_Human_b_.h5\")\n",
    "print(enc_b.summary())\n",
    "\n",
    "feat_b_enc = enc_b.predict(feat_b)\n",
    "print(feat_b_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human new trainning set (8161, 1232)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feat_all_enc = np.concatenate((feat_a_enc, feat_b_enc), axis=1)\n",
    "print('Human new trainning set', feat_all_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_tr = np.copy(feat_all_enc)\n",
    "y_tr = np.copy(label)\n",
    "y_tr[y_tr == -1] = 0\n",
    "print(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StratifiedKFold(n_splits=5, random_state=48, shuffle=True)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For evaluating multiple scores, use sklearn.model_selection.cross_validate instead. ['auc'] was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16980\\2084400963.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\n{cv.__str__()}...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mscr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\thnha\\Anaconda3\\envs\\TFCONDA26\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \"\"\"\n\u001b[0;32m    506\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     cv_results = cross_validate(\n",
      "\u001b[1;32mc:\\Users\\thnha\\Anaconda3\\envs\\TFCONDA26\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;34m\"For evaluating multiple scores, use \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[1;34m\"sklearn.model_selection.cross_validate instead. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             \u001b[1;34m\"{0} was passed.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         )\n\u001b[0;32m    487\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For evaluating multiple scores, use sklearn.model_selection.cross_validate instead. ['auc'] was passed."
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    n_estimators=500, # 500\n",
    "    num_leaves=80,  # 80\n",
    "    learning_rate=0.05\n",
    "    # max_depth=10,\n",
    "    # feature_fraction=0.9,\n",
    "    # bagging_fraction=0.8,\n",
    "    # bagging_freq=5,\n",
    ")\n",
    "\n",
    "# gbm = lgb.LGBMClassifier(**params)\n",
    "\n",
    "# pipeline = Pipeline([('transformer', t), ('estimator', gbm)])\n",
    "cv = StratifiedKFold(n_splits=5, random_state=48, shuffle=True)\n",
    "print(f'\\n{cv.__str__()}...')\n",
    "scr = cross_val_score(estimator=gbm, scoring=['auc'], X=X_tr, y=y_tr, cv=cv, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9816289  0.98651961 0.98223039 0.9810049  0.98835784]\n",
      "mean 0.9839, std 0.003\n"
     ]
    }
   ],
   "source": [
    "print(scr)\n",
    "print(\"mean {:0.4f}, std {:0.3f}\".format(np.mean(scr), np.std(scr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, n_estimators=500, num_leaves=80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "gbm = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    num_leaves=80,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "gbm.fit(X_tr, y_tr.ravel())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST TRÊN TẬP ĐỘC LẬP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\NCSI\\3 - Thuc nghiem\\ModifiedModel\\AE_LGBM_2020\\mod_AE_LGBM\\Independent Species\\Ecoli\")\n",
    "feat_a = pd.read_csv(\"total_features_a.csv\")\n",
    "feat_a = enc_a.predict(feat_a)\n",
    "\n",
    "feat_b = pd.read_csv(\"total_features_b.csv\")\n",
    "feat_b = enc_b.predict(feat_b)\n",
    "\n",
    "data_te = np.concatenate((feat_a, feat_b), axis=1)\n",
    "print('data_te', data_te.shape)\n",
    "label_te = [1] * data_te.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(gbm.score(data_te, label_te))\n",
    "print(\"{:.4f}\".format(gbm.score(data_te, label_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFCONDA26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
